{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: $X = Z + \\epsilon$ where $Z$ and $\\epsilon$ are independent unit normal. \\\n",
    "Then $p(x|z) \\approx \\mathcal{N}(z, 1)$ and $q(z|x) \\approx \\mathcal{N}(x/2,1/\\sqrt{2})$. \\\n",
    "Let's numerically verify this: \n",
    "1. Generate $M$ value pairs for $(X,Z)$ where $X=x$ and verify that $Z$ is approximately $\\mathcal{N}(x/2,1/\\sqrt{2})$\n",
    "2. Generate $M$ value pairs for $(X,Z)$ where $Z=z$ and verify that $X$ is approximately $\\mathcal{N}(z,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fixed_z(value, num):\n",
    "    eps = np.random.normal(0,1, size=num)\n",
    "    return list(zip(eps +value, [value]*num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fixed_x(value, num):\n",
    "    z_minus_eps = np.random.normal(0,1, size=num) - np.random.normal(0,1, size=num)\n",
    "    return list(zip([value]*num, z_minus_eps/2 + value/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_p_x_z():\n",
    "    value = 2\n",
    "    num = 1000000\n",
    "    x_zs = gen_fixed_z(value, num)\n",
    "    xs = [x for (x,z) in x_zs]\n",
    "    assert(stats.jarque_bera(xs)[1] > .05)\n",
    "    plt.hist(xs, bins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_p_x_z()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_q_z_x():\n",
    "    value = 2\n",
    "    num = 1000000\n",
    "    x_zs = gen_fixed_x(value, num)\n",
    "    zs = [z for (x,z) in x_zs]\n",
    "    assert(stats.jarque_bera(zs)[1] >.05)\n",
    "    plt.hist(zs, bins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_q_z_x()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evidence lower bound analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following recogition model: \\\n",
    "$ q(Z|X) \\sim \\mathcal{N}(a_1X + b_1, \\sigma_1) \\ $ and $\\ p(X|Z) \\sim \\mathcal{N}(a_2Z + b_2, \\sigma_2)$ \\\n",
    "and also $Z$ has unit normal prior. Then the evidence lower bound function is\n",
    "\n",
    "$$\\text{elbo}(x,z) = -\\frac{1}{2} \\, z^{2} + \\frac{{\\left(a_{1} x + b_{1} - z\\right)}^{2}}{2 \\, \\sigma_{1}^{2}} - \\frac{{\\left(a_{2} z + b_{2} - x\\right)}^{2}}{2 \\, \\sigma_{2}^{2}} + \\log\\left(\\frac{\\sqrt{2}}{2 \\, \\sqrt{\\pi}}\\right) - \\log\\left(\\frac{1}{\\sigma_{1}}\\right) + \\log\\left(\\frac{1}{\\sigma_{2}}\\right)$$\n",
    "\n",
    "First we expand:\n",
    "$$\\frac{a_{1}^{2} x^{2}}{2 \\, \\sigma_{1}^{2}} - \\frac{a_{2}^{2} z^{2}}{2 \\, \\sigma_{2}^{2}} - \\frac{1}{2} \\, z^{2} + \\frac{a_{1} b_{1} x}{\\sigma_{1}^{2}} - \\frac{a_{2} b_{2} z}{\\sigma_{2}^{2}} - \\frac{a_{1} x z}{\\sigma_{1}^{2}} + \\frac{a_{2} x z}{\\sigma_{2}^{2}} + \\frac{b_{1}^{2}}{2 \\, \\sigma_{1}^{2}} - \\frac{b_{2}^{2}}{2 \\, \\sigma_{2}^{2}} + \\frac{b_{2} x}{\\sigma_{2}^{2}} - \\frac{x^{2}}{2 \\, \\sigma_{2}^{2}} - \\frac{b_{1} z}{\\sigma_{1}^{2}} + \\frac{z^{2}}{2 \\, \\sigma_{1}^{2}} + \\\\ \\log\\left(\\frac{\\sqrt{2}}{2 \\, \\sqrt{\\pi}}\\right) - \\log\\left(\\frac{1}{\\sigma_{1}}\\right) + \\log\\left(\\frac{1}{\\sigma_{2}}\\right)$$\n",
    "\n",
    "and then integrating over $z \\sim \\mathcal{N}(a_1x + b_1, \\sigma_1)$, with $Ez = a_1x + b_1$ amd $Ez^2 = (a_1x+b_1)^2 + \\sigma_1^2$\n",
    "\n",
    "\n",
    "$$\\newcommand{\\Bold}[1]{\\mathbf{#1}}-\\frac{1}{2} \\, a_{1}^{2} x^{2} - \\frac{a_{1}^{2} a_{2}^{2} x^{2}}{2 \\, \\sigma_{2}^{2}} - a_{1} b_{1} x - \\frac{a_{1} a_{2}^{2} b_{1} x}{\\sigma_{2}^{2}} - \\frac{1}{2} \\, b_{1}^{2} - \\frac{1}{2} \\, \\sigma_{1}^{2} - \\frac{a_{2}^{2} b_{1}^{2}}{2 \\, \\sigma_{2}^{2}} - \\frac{a_{2}^{2} \\sigma_{1}^{2}}{2 \\, \\sigma_{2}^{2}} - \\frac{a_{1} a_{2} b_{2} x}{\\sigma_{2}^{2}} + \\frac{a_{1} a_{2} x^{2}}{\\sigma_{2}^{2}} - \\frac{a_{2} b_{1} b_{2}}{\\sigma_{2}^{2}} + \\frac{a_{2} b_{1} x}{\\sigma_{2}^{2}} - \\frac{b_{2}^{2}}{2 \\, \\sigma_{2}^{2}} + \\frac{b_{2} x}{\\sigma_{2}^{2}} - \\frac{x^{2}}{2 \\, \\sigma_{2}^{2}} + \\log\\left(\\sigma_{1}\\right) - \\log\\left(\\sigma_{2}\\right) + \\log\\left(\\frac{\\sqrt{2}}{2 \\, \\sqrt{\\pi}}\\right) + \\frac{1}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we integrate over $x \\sim \\mathcal{N}(0,2)$, with $Ex = 0\\ $ and $\\ Ex^2 = 2$ to get:\n",
    "$$F = \\newcommand{\\Bold}[1]{\\mathbf{#1}}-a_{1}^{2} - \\frac{1}{2} \\, b_{1}^{2} - \\frac{1}{2} \\, \\sigma_{1}^{2} - \\frac{a_{1}^{2} a_{2}^{2}}{\\sigma_{2}^{2}} - \\frac{a_{2}^{2} b_{1}^{2}}{2 \\, \\sigma_{2}^{2}} - \\frac{a_{2}^{2} \\sigma_{1}^{2}}{2 \\, \\sigma_{2}^{2}} - \\frac{a_{2} b_{1} b_{2}}{\\sigma_{2}^{2}} + \\frac{2 \\, a_{1} a_{2}}{\\sigma_{2}^{2}} - \\frac{b_{2}^{2}}{2 \\, \\sigma_{2}^{2}} - \\frac{1}{\\sigma_{2}^{2}} + \\log\\left(\\sigma_{1}\\right) - \\log\\left(\\sigma_{2}\\right) + \\log\\left(\\frac{\\sqrt{2}}{2 \\, \\sqrt{\\pi}}\\right) + \\frac{1}{2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the partial derivatives:\n",
    "\\begin{eqnarray*}\n",
    "\\frac{\\partial{F}}{\\partial{a_1}} &=& -2 \\, a_{1} - \\frac{2 \\, a_{1} a_{2}^{2}}{\\sigma_{2}^{2}} + \\frac{2 \\, a_{2}}{\\sigma_{2}^{2}} \\\\\n",
    "\\frac{\\partial{F}}{\\partial{a_2}} &=& -\\frac{2 \\, a_{1}^{2} a_{2}}{\\sigma_{2}^{2}} - \\frac{a_{2} b_{1}^{2}}{\\sigma_{2}^{2}} - \\frac{a_{2} \\sigma_{1}^{2}}{\\sigma_{2}^{2}} - \\frac{b_{1} b_{2}}{\\sigma_{2}^{2}} + \\frac{2 \\, a_{1}}{\\sigma_{2}^{2}} \\\\\n",
    "\\frac{\\partial{F}}{\\partial{b_1}} &=& \\newcommand{\\Bold}[1]{\\mathbf{#1}}-\\frac{2 \\, a_{1}^{2} b_{1}}{\\sigma_{2}^{2}} - \\frac{a_{2}^{2} b_{1}}{\\sigma_{2}^{2}} - \\frac{b_{1} \\sigma_{1}^{2}}{\\sigma_{2}^{2}} - \\frac{a_{2} b_{2}}{\\sigma_{2}^{2}} + \\frac{2 \\, a_{1}}{\\sigma_{2}^{2}}\\\\\n",
    "\\frac{\\partial{F}}{\\partial{b_2}} &=& \\newcommand{\\Bold}[1]{\\mathbf{#1}}-\\frac{a_{2} b_{1}}{\\sigma_{2}^{2}} - \\frac{b_{2}}{\\sigma_{2}^{2}} \\\\\n",
    "\\frac{\\partial{F}}{\\partial{\\sigma_1}} &=& \\newcommand{\\Bold}[1]{\\mathbf{#1}}-\\sigma_{1} - \\frac{b_{1}^{2} \\sigma_{1}}{\\sigma_{2}^{2}} + \\frac{1}{\\sigma_{1}} \\\\\n",
    "\\frac{\\partial{F}}{\\partial{\\sigma_2}} &=& \\newcommand{\\Bold}[1]{\\mathbf{#1}}\\frac{2 \\, a_{1}^{2} b_{1}^{2}}{\\sigma_{2}^{3}} + \\frac{a_{2}^{2} b_{1}^{2}}{\\sigma_{2}^{3}} + \\frac{b_{1}^{2} \\sigma_{1}^{2}}{\\sigma_{2}^{3}} + \\frac{2 \\, a_{2} b_{1} b_{2}}{\\sigma_{2}^{3}} - \\frac{4 \\, a_{1} b_{1}}{\\sigma_{2}^{3}} + \\frac{b_{2}^{2}}{\\sigma_{2}^{3}} - \\frac{1}{\\sigma_{2}} + \\frac{2}{\\sigma_{2}^{3}}\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that $a_1 = 1/2, a_2 = 1, b_1 = b_2 = 0, \\sigma_1 = 1/\\sqrt{2}, \\sigma_2 = 1$ is a stationary point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run tensorflow to see if it can discover this point by maximizing $F$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(a1,a2,b1,b2,sigma1,sigma2):\n",
    "    return (-a1**2 - 1/2*b1**2 - 1/2*sigma1**2 - a1**2*a2**2/sigma2**2 \n",
    "            -1/2*a2**2*b1**2/sigma2**2 - 1/2*a2**2*sigma1**2/sigma2**2\n",
    "            -a2*b1*b2/sigma2**2 + 2*a1*a2/sigma2**2 - 1/2*b2**2/sigma2**2\n",
    "            -1/sigma2**2 + tf.math.log(sigma1) - tf.math.log(sigma2)\n",
    "            + tf.math.log(1/2*tf.sqrt(2.0)/tf.sqrt(np.pi)) + 1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8, 0.7, 0.7, 0.8, 0.9, 1.4, -4.9189386]\n",
      "[0.26774672, 0.53549397, -2.9368648e-21, 6.7602745e-21, 0.9255394, 1.308911, -1.7655122]\n",
      "[0.26774672, 0.53549397, -3.6871e-41, 8.4872e-41, 0.9255394, 1.308911, -1.7655122]\n",
      "[0.26774672, 0.53549397, -8e-45, 1.5e-44, 0.9255394, 1.308911, -1.7655122]\n",
      "[0.26774672, 0.53549397, -8e-45, 1.5e-44, 0.9255394, 1.308911, -1.7655122]\n",
      "[0.26774672, 0.53549397, -8e-45, 1.5e-44, 0.9255394, 1.308911, -1.7655122]\n",
      "[0.26774672, 0.53549397, -8e-45, 1.5e-44, 0.9255394, 1.308911, -1.7655122]\n",
      "[0.26774672, 0.53549397, -8e-45, 1.5e-44, 0.9255394, 1.308911, -1.7655122]\n",
      "[0.26774672, 0.53549397, -8e-45, 1.5e-44, 0.9255394, 1.308911, -1.7655122]\n",
      "[0.26774672, 0.53549397, -8e-45, 1.5e-44, 0.9255394, 1.308911, -1.7655122]\n"
     ]
    }
   ],
   "source": [
    "a1 = tf.Variable(1.0)\n",
    "b1 = tf.Variable(1.0)\n",
    "a2 = tf.Variable(1.0)\n",
    "b2 = tf.Variable(1.0)\n",
    "sigma1 = tf.Variable(1.0)\n",
    "sigma2 = tf.Variable(1.0)\n",
    "epochs = 10000\n",
    "optimizer = tf.keras.optimizers.Adamax()\n",
    "learning_rate = 0.1\n",
    "for epoch in range(epochs):\n",
    "    with tf.GradientTape() as t:\n",
    "        t.watch([a1, a2, b1, b2, sigma1, sigma2])\n",
    "        F = loss(a1,a2,b1,b2,sigma1,sigma2)\n",
    "        da1, da2, db1, db2, dsigma1, dsigma2 = t.gradient(F, [a1, a2, b1, b2, sigma1, sigma2])\n",
    "        a1.assign_add(learning_rate*da1)\n",
    "        a2.assign_add(learning_rate*da2)\n",
    "        b1.assign_add(learning_rate*db1)\n",
    "        b2.assign_add(learning_rate*db2)\n",
    "        sigma1.assign_add(learning_rate*dsigma1)\n",
    "        sigma2.assign_add(learning_rate*dsigma2)\n",
    "        if epoch % 1000 == 0:\n",
    "            print([x.numpy() for x in [a1,a2,b1,b2,sigma1,sigma2,F]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-1.7655122, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.set_floatx('float32')\n",
    "print(loss(0.5,1.0,0.0,0.0,1/tf.sqrt(2.0),1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many optimal solutions and the analytical solution above is one of them.\\\n",
    "However, the model actually imposes more constraints on the parameters than we have used.\\\n",
    "We can see that\n",
    "\\begin{eqnarray*}\n",
    "EX &=& E_Z(a_2Z+b_2) = b_2 \\\\\n",
    "EX^2 &=& E_Z(a_2Z^2+b_2) =  \\sigma_2^2 + a_2^2 + b_2^2 \\\\\n",
    "EZ^2 &=& E_X(EZ^2|X) = E_X(a_1X + b_1X)^2 + \\sigma_2^2 \\\\\n",
    "&=& a_1^2EX^2  + 2a_1b_1EX + b_1^2 + \\sigma_1^2 \\\\\n",
    "&=& a_1^2(\\sigma_2^2 + a_2^2 + b_2^2) + 2a_1b_1b_2 + b_1^2 + \\sigma_1^2 = 1\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will replace $\\sigma_1^2$ by $1 - a_1^2(\\sigma_2^2 + a_2^2 + b_2^2) - 2a_1b_1b_2 - b_1^2$ and try the optimization again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sigma1(a1,a2,b1,b2,sigma2):\n",
    "    return tf.sqrt(1.0 - a1**2*(sigma2**2 + a2**2 + b2**2) - 2*a1*b1*b2 - b1**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss2(a1,a2,b1,b2,sigma2):\n",
    "    sigma1 = get_sigma1(a1,a2,b1,b2,sigma2)\n",
    "    return loss(a1,a2,b1,b2,sigma1,sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraint(a1,a2,b1,b2,sigma1,sigma2):\n",
    "    return a1**2*(sigma2**2 + a2**2 + b2**2) + 2*a1*b1*b2 + b1**2 + sigma1**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.099657714, 0.10892073, 0.08876026, 0.088986024, 0.9891274, 1.0981951, -1.9251027]\n",
      "[0.07588988, 0.15177853, -5.249129e-05, 0.00036689814, 0.9942241, 1.4060409, -1.7655122]\n",
      "[0.07588961, 0.15177909, -3.4159007e-07, 2.3015466e-06, 0.9942241, 1.4060446, -1.7655122]\n",
      "[0.07588961, 0.15177909, -2.1447066e-09, 1.444878e-08, 0.9942241, 1.4060446, -1.7655122]\n",
      "[0.07588961, 0.15177909, -1.3464203e-11, 9.070763e-11, 0.9942241, 1.4060446, -1.7655122]\n",
      "[0.07588961, 0.15177909, -8.452661e-14, 5.6945133e-13, 0.9942241, 1.4060446, -1.7655122]\n",
      "[0.07588961, 0.15177909, -5.306476e-16, 3.574945e-15, 0.9942241, 1.4060446, -1.7655122]\n",
      "[0.07588961, 0.15177909, -3.3313396e-18, 2.244306e-17, 0.9942241, 1.4060446, -1.7655122]\n",
      "[0.07588961, 0.15177909, -2.091373e-20, 1.408947e-19, 0.9942241, 1.4060446, -1.7655122]\n",
      "[0.07588961, 0.15177909, -1.3129378e-22, 8.845191e-22, 0.9942241, 1.4060446, -1.7655122]\n"
     ]
    }
   ],
   "source": [
    "a1 = tf.Variable(0.1)\n",
    "b1 = tf.Variable(0.1)\n",
    "a2 = tf.Variable(0.1)\n",
    "b2 = tf.Variable(0.1)\n",
    "sigma2 = tf.Variable(1.0)\n",
    "epochs = 1000\n",
    "optimizer = tf.keras.optimizers.Adamax()\n",
    "learning_rate = 0.1\n",
    "for epoch in range(epochs):\n",
    "    with tf.GradientTape() as t:\n",
    "        t.watch([a1, a2, b1, b2, sigma2])\n",
    "        F = loss2(a1,a2,b1,b2,sigma2)\n",
    "        da1, da2, db1, db2, dsigma2 = t.gradient(F, [a1, a2, b1, b2, sigma2])\n",
    "        a1.assign_add(learning_rate*da1)\n",
    "        a2.assign_add(learning_rate*da2)\n",
    "        b1.assign_add(learning_rate*db1)\n",
    "        b2.assign_add(learning_rate*db2)\n",
    "        sigma2.assign_add(learning_rate*dsigma2)\n",
    "        if epoch % 100 == 0:\n",
    "            sigma1 = get_sigma1(a1,a2,b1,b2,sigma2)\n",
    "            print([x.numpy() for x in [a1,a2,b1,b2,sigma1, sigma2,F]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still couldn't get the desired solution. More constraints are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbo(x,z, a1, a2, b1, b2, sigma1, sigma2):\n",
    "    return (-z**2/2 + (a1*x + b1 -z)**2/2/sigma1**2 - (a2**z + b2 -x)**2/2/sigma2**2\n",
    "            + np.log(1/(np.sqrt(2*np.pi))) + np.log(sigma1) - np.log(sigma2) )\n",
    "\n",
    "def elbo_x(x, a1, a2, b1, b2, sigma1, sigma2):\n",
    "    return (-1/2*a1**2*x**2 - a1**2*a2**2*x**2/2/sigma2**2 - a1*b1*x\n",
    "            -a1*a2**2*b1*x/sigma2**2 - b1**2/2 - sigma1**2/2 - a2**2*b1**2/2/sigma2**2\n",
    "            -a2**2*sigma1**2/2/sigma2**2 - a1*a2*b2*x/sigma2**2 + a1*a2*x**2/sigma2**2\n",
    "            -a2*b1*b2/sigma2**2 + a2*b1*x/sigma2**2 -b2**2/2/sigma2**2 + b2*x/sigma2**2\n",
    "            -x**2/2/sigma2**2 + np.log(sigma1) - np.log(sigma2) - np.log(np.sqrt(2*np.pi)) + 1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a1, a2, b1, b2, sigma1, sigma2 = 1.0/2, 1.0, 0.0, 0.0, 1.0/tf.sqrt(2.0), 1.0\n",
    "a1, a2, b1, b2, sigma1, sigma2 = 1.0/2, 1.0, 0.3, 0.7, 1.0/tf.sqrt(2.0), 1.0\n",
    "N = 10000000\n",
    "zs = np.random.normal(0,1, N)\n",
    "xs = zs + np.random.normal(0,1, N)\n",
    "res_x = elbo_x(xs, a1, a2, b1, b2, sigma1, sigma2)\n",
    "res = elbo(xs, zs, a1, a2, b1, b2, sigma1, sigma2)\n",
    "np.mean(res), np.mean(res_x), loss(a1,a2,b1,b2,sigma1,sigma2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
